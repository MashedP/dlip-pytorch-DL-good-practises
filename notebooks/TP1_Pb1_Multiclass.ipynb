{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line to install packages\n",
    "# pip install torch torchvision matplotlib pandas seaborn requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "PyTorch provides two powerful data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as prepare your own data. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "### USPS Dataset\n",
    "* Handwritten digits with 10 classes\n",
    "* 16x16 pixels for each image \n",
    "* 6 000 data examples in training set, 1 291 examples in validation set, 2 007 in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "if not os.path.isdir(\"USPS/\"):\n",
    "    os.mkdir(\"USPS/\")\n",
    "open(\"USPS/usps.bz2\", \"wb\").write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading USPS dataset from torchvision.dataset\n",
    "dataset = torchvision.datasets.USPS(\n",
    "    root=\"USPS/\", train=True, transform=transforms.ToTensor(), download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info from dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the inputs and targets:\n",
    "inputs = dataset.data\n",
    "targets = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a data point\n",
    "sample_index = 88\n",
    "\n",
    "data_sample = dataset.data[sample_index]\n",
    "target_sample = dataset.targets[sample_index]\n",
    "print(\"Sample type and shape : \", type(data_sample), data_sample.shape)\n",
    "print(\"Label type and value : \", type(target_sample), target_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 88\n",
    "plt.imshow(dataset.data[sample_index], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "plt.title(\"image label: %d\" % dataset.targets[sample_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Documentation : https://pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data_point = torch.tensor(data_sample)\n",
    "print(\"Tensor type :\", type(tensor_data_point), \", and shape : \", tensor_data_point.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyplot can manage torch Tensors\n",
    "plt.imshow(tensor_data_point, cmap=plt.cm.gray_r)\n",
    "plt.title(\"Tensor display\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset to training and validation sets\n",
    "train_set, val_set = random_split(dataset, [6000, 1291])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "The `torch.nn` namespace provides all the building blocks you need to create your own neural network such as fully connected layers or convolutional layers etc. We define our neural network by subclassing `nn.Module`, and the neural network layers are initialized in **\\__init\\__**. Every `nn.Module` subclass implements the operations on input data in the **forward** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inheritance in Python (https://www.programiz.com/python-programming/inheritance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"A simple feedforward neural network for multi-class classification.\n",
    "\n",
    "    This model consists of two fully connected layers with ReLU activation\n",
    "    for the hidden layer and softmax activation for the output layer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    l1 : nn.Linear\n",
    "        First linear layer mapping input (256) to hidden layer (100).\n",
    "    l2 : nn.Linear\n",
    "        Second linear layer mapping hidden layer (100) to output (10 classes).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the Model with two linear layers.\"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        # We allocate space for the weights\n",
    "        self.l1 = nn.Linear(16 * 16, 100)\n",
    "        self.l2 = nn.Linear(100, 10)\n",
    "        # Input size is 16*16, output size should be the same with the number of classes\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Perform forward pass through the network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : torch.Tensor\n",
    "            Input tensor of shape (batch_size, 256) representing flattened images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output tensor of shape (batch_size, 10) with class probabilities\n",
    "            (softmax normalized).\n",
    "        \"\"\"\n",
    "        h = F.relu(\n",
    "            self.l1(inputs)\n",
    "        )  # You can put anything, as long as its Pytorch functions\n",
    "        outputs = F.softmax(\n",
    "            self.l2(h), dim=1\n",
    "        )  # Use softmax as the activation function for the last layer\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of AutoGrad (https://pytorch.org/docs/stable/notes/autograd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation and forward call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the Model class\n",
    "my_model = Model()  # it calls the init method\n",
    "print(\" - What is the type of my_model ?\", type(my_model))\n",
    "print(\"=\" * 50)\n",
    "print(\" - Description of the internal of the Network :\", my_model)\n",
    "print(\"=\" * 50)\n",
    "print(\n",
    "    \" - Content of the first Layer :\",\n",
    "    my_model.l1.weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the Linear Layer\n",
    "print(\"A :\", my_model.l1.weight.shape, \" b : \", my_model.l1.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the forward pass\n",
    "example_batch_size = 3\n",
    "example_loader = DataLoader(dataset, batch_size=example_batch_size, shuffle=True)\n",
    "\n",
    "for images, labels in example_loader:\n",
    "    print(\"Original tensor shape\", images.shape)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Impact of the view method\", images.view(example_batch_size, -1).shape)\n",
    "    print(\"=\" * 50)\n",
    "    example_output = my_model(images.view(example_batch_size, -1))\n",
    "    print(\"Shape of the output\", example_output.shape)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Predictions for the first image :\", example_output[0].detach())\n",
    "    print(\"=\" * 50)\n",
    "    print(\n",
    "        \"Sum of all outputs : \", torch.sum(example_output[0])\n",
    "    )  # You should use detach !\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of One Hot Encoding\n",
    "\n",
    "labels_one_hot = torch.FloatTensor(example_batch_size, 10)\n",
    "labels_one_hot.zero_()\n",
    "print(\"Original Labels : \", labels.detach())\n",
    "print(\"=\" * 50)\n",
    "print(\"One Hot encoding :\", labels_one_hot.scatter_(1, labels.view(-1, 1), 1).detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model:\n",
    "model = Model()\n",
    "\n",
    "# Choose the hyperparameters for training:\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "# Use mean squared loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Use SGD optimizer with a learning rate of 0.01\n",
    "# It is initialized on our model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# define a function for training\n",
    "def train(\n",
    "    num_epochs: int,\n",
    "    batch_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset,\n",
    ") -> list[float]:\n",
    "    \"\"\"Train a neural network model on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_epochs : int\n",
    "        Number of complete passes through the training dataset.\n",
    "    batch_size : int\n",
    "        Number of samples per gradient update.\n",
    "    criterion : nn.Module\n",
    "        Loss function to optimize (e.g., nn.MSELoss, nn.CrossEntropyLoss).\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Optimization algorithm (e.g., SGD, Adam).\n",
    "    model : nn.Module\n",
    "        Neural network model to train.\n",
    "    dataset : Dataset\n",
    "        Training dataset containing (image, label) pairs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[float]\n",
    "        List of average training losses for each epoch.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function uses one-hot encoding for labels and MSE loss.\n",
    "    For CrossEntropyLoss, the one-hot encoding should be removed.\n",
    "    \"\"\"\n",
    "    train_error: list[float] = []\n",
    "    train_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    model.train()  # Indicates to the network we are in training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_average_loss: float = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            y_pre = model(images.view(batch_size, -1))\n",
    "            # reshape the inputs from [N, img_shape, img_shape] to [N, img_shape*img_shape]\n",
    "\n",
    "            # One-hot encoding or labels so as to calculate MSE error:\n",
    "            labels_one_hot = torch.FloatTensor(batch_size, 10)\n",
    "            labels_one_hot.zero_()\n",
    "            labels_one_hot.scatter_(1, labels.view(-1, 1), 1)\n",
    "\n",
    "            loss = criterion(y_pre, labels_one_hot)  # Real number\n",
    "            optimizer.zero_grad()  # Set all the parameters gradient to 0\n",
    "            loss.backward()  # Computes  dloss/da for every parameter a which has requires_grad=True\n",
    "            optimizer.step()  # Updates the weights\n",
    "            epoch_average_loss += loss.item() * batch_size / len(dataset)\n",
    "        train_error.append(epoch_average_loss)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_average_loss:.4f}\")\n",
    "    return train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = train(num_epochs, batch_size, criterion, optimizer, model, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training error wrt. the number of epochs:\n",
    "plt.plot(range(1, num_epochs + 1), train_error)\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"Train error\")\n",
    "plt.title(\"Visualization of convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy to evaluate the model\n",
    "@torch.no_grad()\n",
    "def accuracy(dataset: Dataset, model: nn.Module) -> None:\n",
    "    \"\"\"Compute and print the classification accuracy of a model on a dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Dataset\n",
    "        Dataset containing (image, label) pairs to evaluate.\n",
    "    model : nn.Module\n",
    "        Trained neural network model to evaluate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the accuracy percentage to stdout.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function sets the model to evaluation mode and uses no gradient\n",
    "    computation for efficiency. Images are expected to be 16x16 pixels\n",
    "    and will be flattened to 256 features.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct: int = 0\n",
    "    dataloader = DataLoader(dataset)\n",
    "    for images, labels in dataloader:\n",
    "        images = images.view(-1, 16 * 16)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print(f\"Accuracy of the model : {100 * correct.item() / len(dataset):.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(val_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = 66\n",
    "\n",
    "(image, label) = val_set[val_index]\n",
    "output = model(image.view(-1, 16 * 16))\n",
    "_, prediction = torch.max(output.data, 1)\n",
    "\n",
    "plt.imshow(image.view(16, 16), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "plt.title(\"Prediction label: %d\" % prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️  Note on the use of Softmax in the last layer\n",
    "\n",
    "Using a Softmax layer in the last layer of a neural network for multi-class classification is typcally what is not done by default in PyTorch. Instead the transformation into probabilities is done inside the loss function `nn.CrossEntropyLoss`, which combines `nn.LogSoftmax` to compute the log-probabilities and `nn.NLLLoss` (negative log likelihood loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Impact of the architecture of the model\n",
    "Define your own class `Model` to improve the predictions:\n",
    "\n",
    "* The convolutional layer can be a good choice to deal with images. Replace nn.Linear with [nn.Conv2d](https://pytorch.org/docs/stable/nn.html#conv2d).\n",
    "* Try to add more layers (1, 2, 3, more ?)\n",
    "* Change the number of neurons in hidden layers (5, 10, 20, more ?)\n",
    "* Try different activation functions such as [sigmoid](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.sigmoid), [tanh](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.tanh), [relu](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.relu), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Impact of the optimizer\n",
    "Retrain the model by using different parameters of the optimizer; you can change its parameters in the cell initializing it, after the definition of your model.\n",
    "\n",
    "* Use different batch sizes, from 10 to 1 000 for instance\n",
    "* Try different values of the learning rate (between 0.001 and 10), and see how these impact the training process. Do all network architectures react the same way to different learning rates?\n",
    "* Change the duration of the training by increasing the number of epochs\n",
    "* Try other optimizers, such as [Adam](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam) or [RMSprop](https://pytorch.org/docs/stable/optim.html?highlight=rmsprop#torch.optim.RMSprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Impact of the loss function\n",
    "The MSE error is rarely used in this case. The cross entropy loss can be a better choice for multi-classification problems. In pytorch, the cross entropy loss is defined by [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss). Replace the MSE loss by this one to observe its impact.\n",
    "\n",
    "**Note:** In order to use nn.CrossEntropyLoss correctly, don't add an activation function to the last layer of your network. And one-hot encoding is no longer needed to calculate the loss, delete the encoding procedures in function `train`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Prediction on test set\n",
    "\n",
    "Once you have a model that seems satisfying on the validation dataset, you SHOULD evaluate it on a test dataset that has never been used before, to obtain a final accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open(\"USPS/usps.t.bz2\", \"wb\").write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST test set from torchvision.dataset\n",
    "test_set = torchvision.datasets.USPS(\n",
    "    root=\"USPS/\", train=False, transform=transforms.ToTensor(), download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(test_set, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
